#
In our work, we constructed four buildingblock datasets of different scales, denoted as S, M, L, and XL. The L and XL datasets were generated by processing the data with dataprocess.py and then preparing the final datasets using dataprepare.py (with molecular weight thresholds of 150 and 200, respectively, for L and XL). The S and M datasets were derived from the L and XL datasets, respectively, through further clustering based on chemfp (with molecular weight thresholds of 150 and 200 for S and M).

# 1.dataprocess
```bash
cd dataprocess
python dataprocess.py
```

# 2.dataprepare
```bash
python dataprepare.py
```
You will obtain the specified buildingblock library scale's smiles_list.json.gz, mask_dict.json.gz, and the pre-training dataset pretrain.csv in the dataprocess/final directory. Simply copy the contents of the final directory to the syngfn/data path.

# 3.pretrain
[Optional]
If you wish to use the pre-training strategy.
```bash
python pretrain.py
```
After the training is completed, you can find the pre-trained model weights pretrain.ckpt for the specified buildingblock scale in the dataprocess/pretrain directory. Simply copy it to the syngfn/pretrain path.